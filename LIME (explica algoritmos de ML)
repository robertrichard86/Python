import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
import lime
import lime.lime_tabular
import matplotlib.pyplot as plt  # Adicionado para exibir gráficos

# Carregar o arquivo CSV
file_path = "~/Desktop/crisp-QueryResult.csv"
data = pd.read_csv(file_path)

# Manter a coluna 'country' para referência, mas não usá-la no treinamento
countries = data['country']  # Salvar a coluna de países
data = data.drop(columns=['country'])  # Remover a coluna de países dos dados de treinamento

# Tratar valores faltantes
data = data.fillna(data.mean())

# Definir variáveis independentes (X) e dependente (y)
X = data.drop(columns=['total_deaths'])
y = data['total_deaths']

# Dividir os dados em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Treinar o modelo Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Treinar o modelo XGBoost
xgb_model = XGBRegressor(n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)

# Avaliar os modelos
rf_pred = rf_model.predict(X_test)
xgb_pred = xgb_model.predict(X_test)

print(f"Random Forest RMSE: {np.sqrt(mean_squared_error(y_test, rf_pred))}")
print(f"XGBoost RMSE: {np.sqrt(mean_squared_error(y_test, xgb_pred))}")

# LIME para Random Forest
explainer_lime = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X.columns, class_names=['total_deaths'], verbose=True, mode='regression')

# Explicar uma instância específica (primeira linha do conjunto de treino)
exp_rf = explainer_lime.explain_instance(X_train.values[0], rf_model.predict, num_features=len(X.columns))

# Exibir a explicação como um gráfico matplotlib
fig_rf = exp_rf.as_pyplot_figure()
plt.title("Explicação LIME para Random Forest")
plt.show()

# LIME para XGBoost
exp_xgb = explainer_lime.explain_instance(X_train.values[0], xgb_model.predict, num_features=len(X.columns))

# Exibir a explicação como um gráfico matplotlib
fig_xgb = exp_xgb.as_pyplot_figure()
plt.title("Explicação LIME para XGBoost")
plt.show()

# Adicionar a coluna de países de volta ao conjunto de teste para referência
X_test_with_countries = X_test.copy()
X_test_with_countries['country'] = countries.iloc[X_test.index]  # Adicionar a coluna de países ao conjunto de teste

# Exibir o conjunto de teste com os países
print(X_test_with_countries.head())
